{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4efba7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, make_scorer, balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from feature_generator import get_meds_feature, get_demo_features, get_lab_features, get_lab_array, get_df_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c30aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = './data'\n",
    "\n",
    "lab_df_list = ['T_SBP.csv', 'T_creatinine.csv', 'T_HGB.csv', 'T_ldl.csv', 'T_glucose.csv', 'T_DBP.csv']\n",
    "train_id_df = 'train.csv'\n",
    "test_id_df = 'test.csv'\n",
    "label_df = 'T_stage.csv'\n",
    "demo_df = 'T_demo.csv'\n",
    "med_df = 'T_meds.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5aec8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSVs\n",
    "\n",
    "df_label = pd.read_csv(os.path.join(data_loc, label_df))\n",
    "\n",
    "df_train_ids = pd.read_csv(os.path.join(data_loc, train_id_df))\n",
    "df_test_ids = pd.read_csv(os.path.join(data_loc, test_id_df))\n",
    "\n",
    "df_demo = pd.read_csv(os.path.join(data_loc, demo_df))\n",
    "\n",
    "df_meds = pd.read_csv(os.path.join(data_loc, med_df))\n",
    "df_label = pd.read_csv(os.path.join(data_loc, label_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff67022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train:240, num_test:60\n",
      "Train distribution: Counter({False: 159, True: 81}) \n",
      "Test distribution: Counter({False: 41, True: 19})\n"
     ]
    }
   ],
   "source": [
    "# Display train test stats\n",
    "\n",
    "df_label.rename(columns = {'id': 'pid'}, inplace=True)\n",
    "train_ids = df_train_ids.id.tolist()\n",
    "test_ids = df_test_ids.id.tolist()\n",
    "print('num train:{}, num_test:{}'.format(len(train_ids), len(test_ids)))\n",
    "\n",
    "train_count = Counter(df_label[df_label.pid.isin(train_ids)]['Stage_Progress'].tolist())\n",
    "test_count = Counter(df_label[df_label.pid.isin(test_ids)]['Stage_Progress'].tolist())\n",
    "\n",
    "print('Train distribution: {} \\nTest distribution: {}'.format(train_count, test_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f93f220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/himanshusharma/Desktop/Holmusk_Assignment/Solution/feature_generator.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sub.sort_values([\"time\"], inplace = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 12)\n",
      "(array([0, 1]), array([159,  81]))\n",
      "(60, 12)\n",
      "(array([0, 1]), array([41, 19]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/himanshusharma/Desktop/Holmusk_Assignment/Solution/feature_generator.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1.drop_duplicates(inplace=True)\n",
      "/Users/himanshusharma/Desktop/Holmusk_Assignment/Solution/feature_generator.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1.sort_values([\"pid\"], inplace = True)\n"
     ]
    }
   ],
   "source": [
    "# Generate lab features\n",
    "\n",
    "#feature_list = ['val_1st','val_last','time_1st','time_last','val_avg','val_median','val_max','val_min','weighted_average']\n",
    "feature_list = ['weighted_average','last_minus_1st']\n",
    "df_train_lab, df_test_lab = get_lab_features(data_loc, lab_df_list, df_label, train_ids, test_ids)\n",
    "\n",
    "X_train_lab, Y_train_lab, pid_lab_train, lab_header_train = get_lab_array(df_train_lab, feature_list, \n",
    "                                                                          feature_header=[])\n",
    "X_test_lab, Y_test_lab, pid_lab_test, lab_header_test = get_lab_array(df_test_lab, feature_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa265c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 7) (60, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/himanshusharma/Desktop/Holmusk_Assignment/Solution/feature_generator.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_name] = out_list\n"
     ]
    }
   ],
   "source": [
    "# Generate demo features\n",
    "\n",
    "feature_list_demo = ['age','gender', 'race']\n",
    "\n",
    "df_demo.rename(columns = {'id': 'pid'}, inplace = True)\n",
    "df_train_demo, df_test_demo = get_demo_features(df_demo, train_ids, test_ids)\n",
    "#df_train_demo.columns()\n",
    "\n",
    "X_train_demo, demo_header_train, pid_demo_train = get_df_array(df_train_demo)\n",
    "\n",
    "X_test_demo, demo_header_test, pid_demo_test = get_df_array(df_test_demo)\n",
    "\n",
    "print(X_train_demo.shape, X_test_demo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29c191d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (pid_demo_test == pid_lab_test).all()\n",
    "assert (pid_demo_train == pid_lab_train).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8b2e1ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate meds features\n",
    "\n",
    "from feature_generator import get_meds_feature\n",
    "\n",
    "pid_list = df_label.pid.unique().tolist()\n",
    "df_train_meds, df_test_meds = get_meds_feature(df_meds, pid_list, train_ids, test_ids)\n",
    "\n",
    "X_train_meds, meds_header_train, pid_meds_train = get_df_array(df_train_meds)\n",
    "\n",
    "X_test_meds, meds_header_test, pid_meds_test = get_df_array(df_test_meds)\n",
    "\n",
    "# df_train_meds.columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1870b20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240, 8), (60, 8), 8, 8, (240,), (60,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_meds.shape, X_test_meds.shape, len(meds_header_train), len(meds_header_test), pid_meds_train.shape, pid_meds_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659e91c2",
   "metadata": {},
   "source": [
    "#### Lab Longitudinal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbb591d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_lab\n",
    "X_test = X_test_lab\n",
    "\n",
    "Y_train = Y_train_lab\n",
    "Y_test = Y_test_lab\n",
    "\n",
    "header_list = list(lab_header_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfe67bb",
   "metadata": {},
   "source": [
    "#### Lab Longitudinal + Demographic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "010185f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only lab and demo features\n",
    "assert (pid_lab_train == pid_demo_train).all() \n",
    "assert (pid_lab_test == pid_lab_test).all() \n",
    "\n",
    "X_train = np.hstack((X_train_lab, X_train_demo))\n",
    "X_test = np.hstack((X_test_lab, X_test_demo))\n",
    "\n",
    "Y_train = Y_train_lab\n",
    "Y_test = Y_test_lab\n",
    "\n",
    "header_list = list(lab_header_train) + list(demo_header_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f322b",
   "metadata": {},
   "source": [
    "#### Lab Longitudinal + Demographic + Medication Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec44714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data\n",
    "assert (pid_lab_train == pid_demo_train).all() and ( pid_demo_train == pid_meds_train).all()\n",
    "assert (pid_lab_test == pid_lab_test).all() and (pid_lab_test == pid_meds_test).all()\n",
    "\n",
    "X_train = np.hstack((X_train_lab, X_train_demo, X_train_meds))\n",
    "X_test = np.hstack((X_test_lab, X_test_demo, X_test_meds))\n",
    "\n",
    "Y_train = Y_train_lab\n",
    "Y_test = Y_test_lab\n",
    "\n",
    "header_list = list(lab_header_train) + list(demo_header_train) + list(meds_header_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b3ec322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240, 27), (60, 27), 27, (240,), (60,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, len(header_list), Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95420066",
   "metadata": {},
   "source": [
    "## Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e7cea63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.73      0.82       159\n",
      "           1       0.63      0.89      0.73        81\n",
      "\n",
      "    accuracy                           0.78       240\n",
      "   macro avg       0.78      0.81      0.78       240\n",
      "weighted avg       0.83      0.78      0.79       240\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80        41\n",
      "           1       0.58      0.79      0.67        19\n",
      "\n",
      "    accuracy                           0.75        60\n",
      "   macro avg       0.73      0.76      0.73        60\n",
      "weighted avg       0.79      0.75      0.76        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "sscale = StandardScaler()\n",
    "X_train_scaled = sscale.fit_transform(X_train)\n",
    "X_test_scaled = sscale.transform(X_test)\n",
    "\n",
    "# clf = LogisticRegression(random_state=0, penalty='l1', solver='saga' , class_weight = 'balanced', l1_ratio=0.3)\n",
    "# clf = LogisticRegression(random_state=42, class_weight = 'balanced')\n",
    "clf = LogisticRegression(random_state=42, class_weight = {0:0.5, 1:1.75})\n",
    "# clf = LogisticRegression(random_state=0, class_weight = 'balanced',penalty='elasticnet', solver='saga' , l1_ratio = 0.2)\n",
    "\n",
    "model = clf.fit(X_train_scaled, Y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(Y_train, y_train_pred))\n",
    "print(classification_report(Y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd5ac17",
   "metadata": {},
   "source": [
    "## Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ee0c7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 27) (60, 27) (240,) (60,)\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "{'bootstrap': True, 'class_weight': {0: 0.2, 1: 0.8}, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 75, 'oob_score': True}\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "# sample_scorer = make_scorer(recall_score)\n",
    "sample_scorer = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "\n",
    "n_estimators = [10, 50, 75]\n",
    "max_depth = [3,5,10,15]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [5, 10]\n",
    "min_samples_leaf = [2,5]\n",
    "bootstrap = [True]\n",
    "class_weight=[{0:0.5, 1:1.75}, {0:0.2, 1:0.8}]\n",
    "oob_score = [True]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "                #'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'bootstrap': bootstrap, \n",
    "              'class_weight': class_weight,\n",
    "              'oob_score': oob_score}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "# # Random search of parameters, using 3 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "#                                 n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "rf_random = GridSearchCV(estimator = rf, param_grid = random_grid, cv = 4, verbose=3, n_jobs = 10,\n",
    "                        scoring = sample_scorer)\n",
    "# # Fit the random search model\n",
    "rf_random.fit(X_train, Y_train)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f47912d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(class_weight={0: 0.2, 1: 0.8}, max_depth=5,\n",
       "                        min_samples_leaf=2, min_samples_split=10,\n",
       "                        n_estimators=50, oob_score=True),\n",
       " 0.7815819597069597,\n",
       " 0.7625)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_estimator_, rf_random.best_score_, rf_random.best_estimator_.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2126768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90       159\n",
      "           1       0.75      0.98      0.84        81\n",
      "\n",
      "    accuracy                           0.88       240\n",
      "   macro avg       0.87      0.90      0.87       240\n",
      "weighted avg       0.90      0.88      0.88       240\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.61      0.74        41\n",
      "           1       0.52      0.89      0.65        19\n",
      "\n",
      "    accuracy                           0.70        60\n",
      "   macro avg       0.72      0.75      0.69        60\n",
      "weighted avg       0.80      0.70      0.71        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = rf_random.best_estimator_.predict(X_train)\n",
    "y_test_pred = rf_random.best_estimator_.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_train, y_train_pred))\n",
    "print(classification_report(Y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5001cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.84121935e-02, 7.22736604e-02, 2.40736193e-02, 2.52712827e-02,\n",
       "       5.12061966e-02, 1.25101252e-01, 2.70792889e-02, 4.27508037e-02,\n",
       "       4.58579951e-02, 1.05567643e-01, 1.07920660e-01, 2.86136646e-01,\n",
       "       2.62792727e-02, 9.89387994e-03, 7.83653830e-04, 9.31098540e-04,\n",
       "       0.00000000e+00, 6.47722463e-04, 9.07823279e-04, 7.71492560e-05,\n",
       "       1.30448693e-03, 2.49429178e-03, 1.00773656e-03, 1.16419436e-18,\n",
       "       7.39116075e-03, 2.36881922e-03, 4.26166347e-03])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5692f30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>last_minus_1st_ldl</td>\n",
       "      <td>2.031977e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>last_minus_1st_SBP</td>\n",
       "      <td>1.102881e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_average_ldl</td>\n",
       "      <td>1.074928e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>last_minus_1st_glucose</td>\n",
       "      <td>1.019520e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>last_minus_1st_DBP</td>\n",
       "      <td>7.860122e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average_SBP</td>\n",
       "      <td>6.740353e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weighted_average_glucose</td>\n",
       "      <td>5.692980e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weighted_average_HGB</td>\n",
       "      <td>5.217304e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>last_minus_1st_HGB</td>\n",
       "      <td>4.698495e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>last_minus_1st_creatinine</td>\n",
       "      <td>4.467773e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted_average_creatinine</td>\n",
       "      <td>4.192443e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>age</td>\n",
       "      <td>4.057460e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weighted_average_DBP</td>\n",
       "      <td>3.968886e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>metformin_ind</td>\n",
       "      <td>2.324353e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gender</td>\n",
       "      <td>2.245489e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>simvastatin_ind</td>\n",
       "      <td>1.726488e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>carvedilol_ind</td>\n",
       "      <td>1.136512e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rosuvastatin_ind</td>\n",
       "      <td>8.840312e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Black</td>\n",
       "      <td>6.517690e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>atorvastatin_ind</td>\n",
       "      <td>6.390775e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Asian</td>\n",
       "      <td>5.485577e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>losartan_ind</td>\n",
       "      <td>4.897335e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>4.534057e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>White</td>\n",
       "      <td>4.454731e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>atenolol_ind</td>\n",
       "      <td>5.400448e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lovastatin_ind</td>\n",
       "      <td>8.149361e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature  feature_importance\n",
       "11           last_minus_1st_ldl        2.031977e-01\n",
       "5            last_minus_1st_SBP        1.102881e-01\n",
       "10         weighted_average_ldl        1.074928e-01\n",
       "9        last_minus_1st_glucose        1.019520e-01\n",
       "1            last_minus_1st_DBP        7.860122e-02\n",
       "4          weighted_average_SBP        6.740353e-02\n",
       "8      weighted_average_glucose        5.692980e-02\n",
       "2          weighted_average_HGB        5.217304e-02\n",
       "3            last_minus_1st_HGB        4.698495e-02\n",
       "7     last_minus_1st_creatinine        4.467773e-02\n",
       "6   weighted_average_creatinine        4.192443e-02\n",
       "12                          age        4.057460e-02\n",
       "0          weighted_average_DBP        3.968886e-02\n",
       "24                metformin_ind        2.324353e-02\n",
       "13                       gender        2.245489e-02\n",
       "26              simvastatin_ind        1.726488e-02\n",
       "21               carvedilol_ind        1.136512e-02\n",
       "25             rosuvastatin_ind        8.840312e-03\n",
       "15                        Black        6.517690e-03\n",
       "20             atorvastatin_ind        6.390775e-03\n",
       "14                        Asian        5.485577e-03\n",
       "22                 losartan_ind        4.897335e-03\n",
       "17                      Unknown        4.534057e-03\n",
       "18                        White        4.454731e-03\n",
       "19                 atenolol_ind        5.400448e-04\n",
       "23               lovastatin_ind        8.149361e-18\n",
       "16                     Hispanic        0.000000e+00"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = rf_random.best_estimator_.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf_random.best_estimator_.estimators_], axis=0)\n",
    "\n",
    "final_feat_imp_df = pd.DataFrame(columns = ['feature', 'feature_importance'])\n",
    "for i, j in zip(header_list, std):\n",
    "    final_feat_imp_df = final_feat_imp_df.append({'feature': i, 'feature_importance':j},ignore_index=True)\n",
    "final_feat_imp_df.sort_values(by='feature_importance', ascending=False, inplace = True)\n",
    "\n",
    "final_feat_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "109b40b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_minus_1st_ldl,20.32\n",
      "last_minus_1st_SBP,11.03\n",
      "weighted_average_ldl,10.75\n",
      "last_minus_1st_glucose,10.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['last_minus_1st_ldl',\n",
       " 'last_minus_1st_SBP',\n",
       " 'weighted_average_ldl',\n",
       " 'last_minus_1st_glucose']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_final_feat_imp_df = final_feat_imp_df[final_feat_imp_df['feature_importance']> 0.1]\n",
    "for ind, row in sub_final_feat_imp_df.iterrows():\n",
    "    print('{},{}'.format(row['feature'], round(row['feature_importance']*100,2)))\n",
    "    \n",
    "sub_final_feat_imp_df['feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0422935a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c93cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test_pred).to_csv('y_test_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef8bb13",
   "metadata": {},
   "source": [
    "## Model 3: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec25b206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 27) (60, 27) (240,) (60,)\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "{'C': 50, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "sscale = StandardScaler()\n",
    "X_train_scaled = sscale.fit_transform(X_train)\n",
    "X_test_scaled = sscale.transform(X_test)\n",
    "\n",
    "sample_scorer = make_scorer(balanced_accuracy_score)\n",
    "# sample_scorer = make_scorer(recall_score)\n",
    "\n",
    "print(X_train_scaled.shape, X_test_scaled.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "param_grid = {'C': [50,100,150,200], 'gamma': [0.1,0.01, 0.02, 0.05, 0.07],'kernel': ['rbf', 'poly', 'sigmoid'], \n",
    "             'class_weight':['balanced', {0:0.5, 1:1.75}]}\n",
    "\n",
    "base_estimator = SVC()\n",
    "\n",
    "sh = GridSearchCV(estimator = base_estimator, param_grid = param_grid, cv = 4, verbose=3, n_jobs = 10, scoring = sample_scorer)\n",
    "# # Fit the random search model\n",
    "sh.fit(X_train, Y_train)\n",
    "print(sh.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "620ccd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SVC(C=50, class_weight='balanced', gamma=0.1, kernel='poly'),\n",
       " 0.6172046703296703)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh.best_estimator_, sh.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "118d50f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 27) (60, 27) (240,) (60,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95       159\n",
      "           1       0.85      1.00      0.92        81\n",
      "\n",
      "    accuracy                           0.94       240\n",
      "   macro avg       0.93      0.96      0.94       240\n",
      "weighted avg       0.95      0.94      0.94       240\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79        41\n",
      "           1       0.55      0.58      0.56        19\n",
      "\n",
      "    accuracy                           0.72        60\n",
      "   macro avg       0.68      0.68      0.68        60\n",
      "weighted avg       0.72      0.72      0.72        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "sscale = StandardScaler()\n",
    "X_train_scaled = sscale.fit_transform(X_train)\n",
    "X_test_scaled = sscale.transform(X_test)\n",
    "\n",
    "sample_scorer = make_scorer(balanced_accuracy_score)\n",
    "# sample_scorer = make_scorer(recall_score)\n",
    "\n",
    "print(X_train_scaled.shape, X_test_scaled.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "sh = SVC(C=100, class_weight={0: 0.5, 1: 1.75}, gamma=0.01)\n",
    "sh.fit(X_train_scaled, Y_train)\n",
    "\n",
    "y_train_pred = sh.predict(X_train_scaled)\n",
    "y_test_pred = sh.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(Y_train, y_train_pred))\n",
    "print(classification_report(Y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3260fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b62945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
